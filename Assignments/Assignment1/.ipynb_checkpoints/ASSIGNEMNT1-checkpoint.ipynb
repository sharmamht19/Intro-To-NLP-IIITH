{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf7c0c8b",
   "metadata": {},
   "source": [
    "# TASK \n",
    "\n",
    "1. Tokenization.--> Done \n",
    "2. N-grams. --> going \n",
    "3. Smoothing and Interpolation.\n",
    "   (a) Good Turing.\n",
    "   (b) Interpolation.\n",
    "4. Generation and Analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "88c5df01",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing \n",
    "import re\n",
    "import string\n",
    "import os\n",
    "from collections import Counter\n",
    "import json\n",
    "import random\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73bb6c64",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f676e945",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_sentences(text):\n",
    "    sentence_regex = r'(?<=\\.|\\?|\\s)\\s+'\n",
    "    sentenced_text = re.split(sentence_regex, text)\n",
    "    return  sentenced_text\n",
    "\n",
    "def sentence_tokenizer(sentence):\n",
    "    # Define regex patterns\n",
    "    word_regex = r'\\w+'\n",
    "    number_regex = r'\\b\\d+\\b'\n",
    "    mailid_regex = r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b'\n",
    "    punctuation_regex = r'[^\\w\\s]'\n",
    "    url_regex = r'https?://\\S+|www\\.\\S+'\n",
    "    hashtag_regex = r'#\\w+'\n",
    "    mention_regex = r'@\\w+'\n",
    "    \n",
    "     # Replacing mails\n",
    "    sentence = re.sub(mailid_regex, \"<MAILID>\", sentence)\n",
    "\n",
    "    # Replacing URLs\n",
    "    sentence = re.sub(url_regex, \"<URL>\", sentence)\n",
    "\n",
    "    # Replacing mentions\n",
    "    sentence = re.sub(mention_regex, \"<MENTION>\", sentence)\n",
    "\n",
    "    # Replacing hashtags\n",
    "    sentence = re.sub(hashtag_regex, \"<HASHTAG>\", sentence)\n",
    "\n",
    "    # Replacing numbers\n",
    "    sentence = re.sub(number_regex, \"<NUM>\", sentence)\n",
    "\n",
    "    # yet to implement some new things....\n",
    "\n",
    "    # Word tokenizer\n",
    "    words = re.findall(word_regex, sentence)\n",
    "\n",
    "    tokenized_sentence =[\"<SOS>\"] +  words + [\"<EOS>\"]  # Append End of sentence to the list of words\n",
    "\n",
    "    return tokenized_sentence\n",
    "    \n",
    "def Tokenizer(text):\n",
    "    # Split the given text into sentences.\n",
    "    sentenced_text = split_sentences(text)\n",
    "    \n",
    "    # final tokeninzed tokens.\n",
    "    tokenized_sentences = []\n",
    "    \n",
    "    for sentence in sentenced_text:\n",
    "         tokenized_sentences.append(sentence_tokenizer(sentence))\n",
    "       \n",
    "    \n",
    "#     print(\"Tokenized Sentences final:\", tokenized_sentences)\n",
    "    \n",
    "    return tokenized_sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06df448d",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9d4a1c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['<SOS>', 'click', 'here', 'to', 'know', 'more', 'about', 'me', 'website', 'URL', 'HASHTAG', 'MENTION', 'sent', 'an', 'email', 'to', 'MAILID', '<EOS>']]\n"
     ]
    }
   ],
   "source": [
    "# Example usage:\n",
    "text = \"click here to know more about me website: https://mohit.com! #exciting @allu sent an email to sharma@gmail.com.\"\n",
    "tokenized_result = Tokenizer(text)\n",
    "print(tokenized_result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b265294",
   "metadata": {},
   "source": [
    "## N - gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66c76718",
   "metadata": {},
   "outputs": [],
   "source": [
    "def BuildNGram(n:int, txt :string):\n",
    "    \n",
    "# def BuildNGram(txt: str, n: int) -> Tuple[Dict[str, List[str]], Dict[str, int]]:\n",
    "\n",
    "    nGramContext = {} # dictionaries to store N-gram context\n",
    "    nGramCounter = {} # dictionaries to store N-gram count\n",
    "\n",
    "    # Tokenizing the input text \n",
    "    sentences = Tokenizer(txt)\n",
    "\n",
    "    for sentence in sentences:\n",
    "        sentence_lower = [word.lower() for word in sentence]\n",
    "        sentence = [\"SOS>\"] *(n-1) + sentence_lower\n",
    "\n",
    "        # Tokenize the sentence\n",
    "        tokens = sentence\n",
    "\n",
    "        # Iterate through N-grams in the sentence\n",
    "        for i in range(len(tokens) - n + 1):\n",
    "            context = \" \".join(tokens[i:i + n - 1])\n",
    "            targetWord = tokens[i + n - 1]\n",
    "            totalNGram = context + \" \" + targetWord if context else targetWord\n",
    "\n",
    "            # Update N-gram counters\n",
    "            if totalNGram in nGramCounter:\n",
    "                nGramCounter[totalNGram] += 1\n",
    "            else:\n",
    "                nGramCounter[totalNGram] = 1\n",
    "\n",
    "                # Update N-gram context\n",
    "                if context in nGramContext:\n",
    "                    nGramContext[context].append(targetWord)\n",
    "                else:\n",
    "                    nGramContext[context] = [targetWord]\n",
    "\n",
    "    return nGramContext, nGramCounter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71d9157a",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b068f6ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'SOS> SOS> <sos>': 2, 'SOS> <sos> this': 1, '<sos> this is': 1, 'this is a': 1, 'is a mohit': 1, 'a mohit sharma': 2, 'mohit sharma <eos>': 2, 'SOS> <sos> han': 1, '<sos> han han': 1, 'han han a': 1, 'han a mohit': 1}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "text = \"This is a mohit sharma. han han a MOHIT Sharma.\"\n",
    "n = 3\n",
    "nGramContext, nGramCounter = BuildNGram(n, text)\n",
    "print(nGramCounter)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4da990cb",
   "metadata": {},
   "source": [
    "## N gram generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3da0ccfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_ngram_model(N, corpus_path):\n",
    "\n",
    "    # Read the corpus from the file\n",
    "    with open(corpus_path, 'r', encoding='utf-8') as file:\n",
    "        corpus = file.read()\n",
    "\n",
    "    # Generate N-grams using the BuildNGram function\n",
    "    nGramContext, nGramCounter = BuildNGram(N, corpus)\n",
    "\n",
    "    return nGramContext, nGramCounter\n",
    "\n",
    "def process_directory(directory_path, N):\n",
    "    # Get a list of all files in the directory\n",
    "    files = [f for f in os.listdir(directory_path) if f.endswith('.txt')]\n",
    "\n",
    "    # Iterate over each file and apply the generate_ngram_model function\n",
    "    for file_name in files:\n",
    "        file_path = os.path.join(directory_path, file_name)\n",
    "        nGramContext, nGramCounter = generate_ngram_model(N, file_path)\n",
    "        # Print the N-gram context and counts\n",
    "        print(\"N-Gram Context:\")\n",
    "        print(nGramContext)\n",
    "\n",
    "        print(\"\\nN-Gram Counts:\")\n",
    "        print(nGramCounter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "345b71b3",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f8f5f814",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['3_g_sample_corpus.txt.json', '.DS_Store', 'corpus', '3_g_sample_corpus.txt_test.txt', 'output.json', 'ASSIGNEMNT1.ipynb', 'sample_corpus.txt', '.ipynb_checkpoints', 'INLP_Assignment_1.pdf', '3_g_sample_corpus.txt_train.txt']\n"
     ]
    }
   ],
   "source": [
    "N = 2\n",
    "corpus_path = \"./corpus\"\n",
    "print(os.listdir(os.getcwd()))\n",
    "# nGramContext , nGramCounter =  process_directory(corpus_path, N)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "488432a2",
   "metadata": {},
   "source": [
    "## Good Turing smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0fed781a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_of_counts(ngram_counter):\n",
    "    count_of_counts_dict = {}\n",
    "    \n",
    "    for count in ngram_counter.values():\n",
    "        count_of_counts_dict[count] = count_of_counts_dict.get(count, 0) + 1\n",
    "    \n",
    "    return count_of_counts_dict\n",
    "\n",
    "def good_turing_smoothing(ngram_counter):\n",
    "    total_ngrams = float(sum(ngram_counter.values()))\n",
    "    \n",
    "#     # Print each key-value pair on a new line\n",
    "#     for ngram, count in ngram_counter.items():\n",
    "#         print(f\"{ngram}: {count}\")\n",
    "#     print(total_ngrams)\n",
    "    # Calculate adjusted counts (c*)\n",
    "    adjusted_counts = {}\n",
    "    \n",
    "    count_of_counts_dict = count_of_counts(ngram_counter)\n",
    "\n",
    "#     print(count_of_counts_dict)\n",
    "#     count_of_counts(ngram_counter)\n",
    "\n",
    "    for count in ngram_counter.values():\n",
    "#         print(count)\n",
    "        Nc_plus_1 = count_of_counts_dict.get(count + 1, 1)\n",
    "        Nc = count_of_counts_dict.get(count, 1)\n",
    "        c_star = (count + 1) * (Nc_plus_1 / Nc) \n",
    "        adjusted_counts[count] = c_star\n",
    "#     print(adjusted_counts)\n",
    "    \n",
    "    # Calculating probabilities after Good-Turing smoothing\n",
    "    smoothed_ngram_probs = {}\n",
    "    for ngram, count in ngram_counter.items():\n",
    "        c_star = adjusted_counts.get(count, 1) \n",
    "        probability = c_star / total_ngrams\n",
    "        smoothed_ngram_probs[ngram] = probability\n",
    "\n",
    "    # Assigning the probabilities for N-grams which havn't seen yet\n",
    "    unseen_ngrams = 1 / total_ngrams\n",
    "    smoothed_ngram_probs[None] = unseen_ngrams\n",
    "\n",
    "    return smoothed_ngram_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c3716f56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.0\n",
      "SOS> SOS> <sos>: 0.07142857142857142\n",
      "SOS> <sos> this: 0.05357142857142857\n",
      "<sos> this is: 0.05357142857142857\n",
      "this is a: 0.05357142857142857\n",
      "is a mohit: 0.05357142857142857\n",
      "a mohit sharma: 0.07142857142857142\n",
      "mohit sharma <eos>: 0.07142857142857142\n",
      "SOS> <sos> han: 0.05357142857142857\n",
      "<sos> han han: 0.05357142857142857\n",
      "han han a: 0.05357142857142857\n",
      "han a mohit: 0.05357142857142857\n",
      "None: 0.07142857142857142\n"
     ]
    }
   ],
   "source": [
    "# Example usage:\n",
    "text = \"This is a mohit sharma. han han a MOHIT Sharma.\"\n",
    "n = 3\n",
    "nGramContext, nGramCounter = BuildNGram(n, text)\n",
    "\n",
    "# Apply Good-Turing smoothing\n",
    "smoothed_probs = good_turing_smoothing(nGramCounter)\n",
    "\n",
    "# Display the smoothed probabilities\n",
    "for ngram, prob in smoothed_probs.items():\n",
    "    print(f\"{ngram}: {prob}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c3fb609",
   "metadata": {},
   "source": [
    "## Interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "db93d40d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_lambdas(trigram_counts, bigram_counts, unigram_counts, lambdas):\n",
    "    updated_lambdas = {f'lambda{i}': lambdas[f'lambda{i}'] for i in range(1, 4)}\n",
    "    total_unigram = float(sum(unigram_counts.values()))\n",
    "    for trigram, trigram_count in trigram_counts.items():\n",
    "        t1, t2, t3 = trigram.split()\n",
    "\n",
    "        # Check if the frequency of the trigram is greater than 0\n",
    "        if trigram_count > 0:\n",
    "            # Calculate the three conditions\n",
    "            condition1 = (trigram_count - 1) / max(1, bigram_counts.get(f'{t1} {t2}', 0) - 1)\n",
    "            condition2 = (bigram_counts.get(f'{t2} {t3}', 0) - 1) / max(1, unigram_counts.get(t2, 0) - 1)\n",
    "            condition3 = (unigram_counts.get(t3, 0) - 1) / max(1, total_unigram - 1)\n",
    "\n",
    "            # Find the index of the maximum condition\n",
    "            max_condition_index = max(enumerate([condition1, condition2, condition3]), key=lambda x: x[1])[0]\n",
    "#             print(condition1)\n",
    "#             print(condition2)\n",
    "#             print(condition3)\n",
    "#             print(max_condition_index)\n",
    "#             print(\"---------\")\n",
    "            \n",
    "            # Update lambdas based on the maximum condition\n",
    "            updated_lambdas[f'lambda{max_condition_index + 1}'] += trigram_count\n",
    "#             print(updated_lambdas)\n",
    "            \n",
    "    # Normalize the lambdas to ensure they sum to 1\n",
    "    lambda_sum = sum(updated_lambdas.values())\n",
    "    normalized_lambdas = {key: value / lambda_sum for key, value in updated_lambdas.items()}\n",
    "\n",
    "    return normalized_lambdas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "87436613",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_interpolation_smoothing(trigram_counts, bigram_counts, unigram_counts, is_train=False, lambdas=None):\n",
    "    total_trigrams = sum(trigram_counts.values())\n",
    "    total_bigrams = sum(bigram_counts.values())\n",
    "    total_unigrams = sum(unigram_counts.values())\n",
    "\n",
    "    interpolated_probs = {}\n",
    "    \n",
    "    if is_train:\n",
    "        lambdas = {f'lambda{i}': 0.0 for i in range(1, 4)}\n",
    "        lambdas = update_lambdas(trigram_counts, bigram_counts, unigram_counts, lambdas)\n",
    "\n",
    "    for trigram, count in trigram_counts.items():\n",
    "        t1, t2, t3 = trigram.split()\n",
    "\n",
    "        # Unigram probability\n",
    "        P1_t3 = unigram_counts.get(t3, 0) / total_unigrams\n",
    "\n",
    "        # Bigram probability\n",
    "        P2_t3 = bigram_counts.get(f\"{t2} {t3}\", 0) / total_bigrams\n",
    "\n",
    "        # Trigram probability\n",
    "        P3_t3 = count / total_trigrams\n",
    "\n",
    "        # Interpolation weights\n",
    "        lambda1 = lambdas.get('lambda1', 1/3.0)\n",
    "        lambda2 = lambdas.get('lambda2', 1/3.0)\n",
    "        lambda3 = lambdas.get('lambda3', 1/3.0)\n",
    "\n",
    "        # Linear interpolation\n",
    "        interpolated_prob = lambda1 * P1_t3 + lambda2 * P2_t3 + lambda3 * P3_t3\n",
    "\n",
    "        interpolated_probs[trigram] = interpolated_prob\n",
    "\n",
    "    if is_train:\n",
    "        return interpolated_probs, lambdas\n",
    "    else:\n",
    "        return interpolated_probs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a55daf7e",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1af6eb36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: a b c: 0.3041666666666667\n",
      "Training: b c d: 0.22916666666666669\n",
      "Training: c d e: 0.020833333333333336\n",
      "Testing: x y z: 0.30666666666666664\n",
      "Testing: y z w: 0.20444444444444446\n",
      "Testing: z w v: 0.013333333333333334\n"
     ]
    }
   ],
   "source": [
    "# Example usage during training:\n",
    "trigram_counts_train = {'a b c': 5, 'b c d': 3, 'c d e': 2}\n",
    "bigram_counts_train = {'a b': 10, 'b c': 8, 'c d': 6}\n",
    "unigram_counts_train = {'a': 15, 'b': 12, 'c': 9, 'd': 7, 'e': 5}\n",
    "\n",
    "# Set is_train to True during training\n",
    "interpolated_probs_train, updated_lambdas = linear_interpolation_smoothing(trigram_counts_train, bigram_counts_train, unigram_counts_train, is_train=True)\n",
    "\n",
    "# Example usage during testing with updated lambdas:\n",
    "trigram_counts_test = {'x y z': 4, 'y z w': 2, 'z w v': 1}\n",
    "bigram_counts_test = {'x y': 8, 'y z': 6, 'z w': 4}\n",
    "unigram_counts_test = {'x': 10, 'y': 8, 'z': 6, 'w': 4, 'v': 2}\n",
    "\n",
    "# Set is_train to False during testing and pass updated lambdas\n",
    "interpolated_probs_test = linear_interpolation_smoothing(trigram_counts_test, bigram_counts_test, unigram_counts_test, is_train=False, lambdas=updated_lambdas)\n",
    "\n",
    "# Display the interpolated probabilities during training\n",
    "for trigram, prob in interpolated_probs_train.items():\n",
    "    print(f\"Training: {trigram}: {prob}\")\n",
    "\n",
    "# Display the interpolated probabilities during testing\n",
    "for trigram, prob in interpolated_probs_test.items():\n",
    "    print(f\"Testing: {trigram}: {prob}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b776afd",
   "metadata": {},
   "source": [
    "## Model Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "fd960e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(self, corpus_path, n_gram_order=3, smoothing_type=\"g\", lambdas=None):\n",
    "        self.n_gram_order = n_gram_order\n",
    "        self.smoothing_type = smoothing_type\n",
    "        self.lambdas = lambdas\n",
    "        self.corpus_path = corpus_path\n",
    "        self.save_file_path = self._get_save_file_path(0)\n",
    "        self.train_corpus_path = self._get_save_file_path(1)\n",
    "        self.test_corpus_path = self._get_save_file_path(2)\n",
    "        self.test_samples_count = 1\n",
    "        self.nGramContext = None\n",
    "        self.nGramCounter = None\n",
    "        self.probs = None\n",
    "\n",
    "    def _get_save_file_path(self, file_type):\n",
    "        # Extract the base name of the corpus path\n",
    "        corpus_name = os.path.basename(self.corpus_path) if self.corpus_path else \"corpus_unknown.txt\"\n",
    "\n",
    "        if file_type == 0:\n",
    "            return f\"{self.n_gram_order}_{self.smoothing_type}_{corpus_name}.json\"\n",
    "        elif file_type == 1:\n",
    "            return f\"{self.n_gram_order}_{self.smoothing_type}_{corpus_name}_train.txt\"\n",
    "        elif file_type == 2:\n",
    "            return f\"{self.n_gram_order}_{self.smoothing_type}_{corpus_name}_test.txt\"\n",
    "        else:\n",
    "            raise ValueError(\"Invalid file_type. Use 0 for save_file, 1 for train_corpus, and 2 for test_corpus.\")\n",
    "\n",
    "    \n",
    "    def setup(self, corpus_path=None):\n",
    "        # If corpus_path is not provided, use the path stored in self.corpus_path\n",
    "        if corpus_path is None:\n",
    "            corpus_path = self.corpus_path\n",
    "\n",
    "        # Read the corpus from the file\n",
    "        with open(corpus_path, 'r', encoding='utf-8') as file:\n",
    "            corpus = file.read()\n",
    "\n",
    "        # Split the corpus into sentences\n",
    "        sentences = split_sentences(corpus)\n",
    "        # Exclude sentences with zero words\n",
    "        sentences = [sentence for sentence in sentences if len(sentence.split()) > 0]\n",
    "#         for s in sentences:\n",
    "#             print(s)\n",
    "#             print(\"--------------------\")\n",
    "        # Randomly select 1000 sentences for testing\n",
    "        selected_sentences = random.sample(sentences, min(self.test_samples_count, len(sentences)))\n",
    "\n",
    "        # Write the selected sentences to the test corpus file\n",
    "        with open(self.test_corpus_path, 'w', encoding='utf-8') as test_file:\n",
    "            test_file.write(\"\\n\".join(selected_sentences))\n",
    "\n",
    "        # Write the remaining sentences to the train corpus file\n",
    "        remaining_sentences = [sentence for sentence in sentences if sentence not in selected_sentences]\n",
    "        with open(self.train_corpus_path, 'w', encoding='utf-8') as train_file:\n",
    "            train_file.write(\"\\n\".join(remaining_sentences))\n",
    "\n",
    "        print(f\"Setup complete. Train corpus: {self.train_corpus_path}, Test corpus: {self.test_corpus_path}\")\n",
    "\n",
    "\n",
    "    def train(self):\n",
    "        self.nGramContext, self.nGramCounter = generate_ngram_model(self.n_gram_order, self.corpus_path)\n",
    "\n",
    "        if self.smoothing_type == \"g\":\n",
    "            self.probs = good_turing_smoothing(self.nGramCounter)\n",
    "#             print(self.probs)\n",
    "        elif self.smoothing_type == \"i\":\n",
    "            self.probs, self.lambdas = linear_interpolation_smoothing(self.nGramCounter, is_train=True, lambdas=self.lambdas\n",
    "            )\n",
    "        else:\n",
    "            raise ValueError(\"Invalid smoothing type. Choose 'good_turing' or 'linear_interpolation'.\")\n",
    "\n",
    "    def save(self):\n",
    "        # Save all necessary variables to a JSON file\n",
    "        model_state = {\n",
    "            'n_gram_order': self.n_gram_order,\n",
    "            'probs': self.probs,\n",
    "            'lambdas': self.lambdas,\n",
    "            'nGramContext': self.nGramContext,\n",
    "            'nGramCounter': self.nGramCounter,\n",
    "        }\n",
    "\n",
    "        with open(self.save_file_path, 'w') as file:\n",
    "            json.dump(model_state, file)\n",
    "\n",
    "    def load(self):\n",
    "        # Load all necessary variables from a JSON file\n",
    "        with open(self.save_file_path, 'r') as file:\n",
    "            model_state = json.load(file, object_hook=self.json_object_hook)\n",
    "\n",
    "        self.n_gram_order = model_state['n_gram_order']\n",
    "        self.probs = model_state['probs']\n",
    "        self.lambdas = model_state['lambdas']\n",
    "        self.nGramContext = model_state['nGramContext']\n",
    "        self.nGramCounter = model_state['nGramCounter']\n",
    "\n",
    "    def json_object_hook(self, dct):\n",
    "        # Replace the key 'null' with None during JSON deserialization\n",
    "        return {key if key != 'null' else None: value for key, value in dct.items()}\n",
    "\n",
    "    \n",
    "    def perplexity(self, sentence):\n",
    "        tokenized_sentence = sentence_tokenizer(sentence)\n",
    "        total_words = len(tokenized_sentence) - 2  # Exclude <SOS> and <EOS>\n",
    "        if len(tokenized_sentence) - 2 == 0:\n",
    "            print(sentence)\n",
    "        # Calculate the log likelihood of the sentence using the model probabilities\n",
    "        log_likelihood_sentence = 0.0\n",
    "        for i in range(self.n_gram_order - 1, len(tokenized_sentence)):\n",
    "            context = \" \".join(tokenized_sentence[i - self.n_gram_order + 1: i])\n",
    "            target_word = tokenized_sentence[i]\n",
    "            n_gram = f\"{context} {target_word}\" if context else target_word\n",
    "\n",
    "            # Calculate log likelihood based on the model probabilities\n",
    "            log_likelihood_sentence += math.log(self.probs.get(n_gram, self.probs[None]))\n",
    "\n",
    "        perplexity_sentence = 2 ** (-log_likelihood_sentence / total_words)\n",
    "        return perplexity_sentence, log_likelihood_sentence\n",
    "    \n",
    "    def perplexity_of_ts(self, tokenized_sentence):\n",
    "        total_words = len(tokenized_sentence) - 2  # Exclude <SOS> and <EOS>\n",
    "        log_likelihood_sentence = 0.0\n",
    "        for i in range(self.n_gram_order - 1, len(tokenized_sentence)):\n",
    "            context = \" \".join(tokenized_sentence[i - self.n_gram_order + 1: i])\n",
    "            target_word = tokenized_sentence[i]\n",
    "            n_gram = f\"{context} {target_word}\" if context else target_word\n",
    "\n",
    "            # Calculate log likelihood based on the model probabilities\n",
    "            log_likelihood_sentence += math.log(self.probs.get(n_gram, self.probs[None]))\n",
    "\n",
    "        perplexity_sentence = 2 ** (-log_likelihood_sentence / total_words)\n",
    "        return perplexity_sentence, log_likelihood_sentence\n",
    "\n",
    "    def evaluate(self, train=True, test=False):\n",
    "        if train:\n",
    "            corpus_path = self.train_corpus_path\n",
    "        elif test:\n",
    "            corpus_path = self.test_corpus_path\n",
    "        else:\n",
    "            raise ValueError(\"Either train or test flag should be True.\")\n",
    "\n",
    "        # Read the corpus from the file\n",
    "        with open(corpus_path, 'r', encoding='utf-8') as file:\n",
    "            corpus = file.read()\n",
    "\n",
    "        sentences = split_sentences(corpus)\n",
    "        # Exclude sentences with zero words\n",
    "#         sentences = [sentence for sentence in sentences if len(sentence.split()) > 0]\n",
    "        \n",
    "#         print(sentences)\n",
    "        total_words = 0\n",
    "        log_likelihood_sum = 0.0\n",
    "        perplexity_scores = []\n",
    "\n",
    "        for sentence in sentences:\n",
    "            tokenized_sentence = sentence_tokenizer(sentence)\n",
    "            if len(tokenized_sentence) > self.n_gram_order:\n",
    "                perplexity_sentence, log_likelihood_sentence = self.perplexity_of_ts(sentence)\n",
    "                perplexity_scores.append(perplexity_sentence)\n",
    "#                 print(sentence , \" : perplexity  score : \",perplexity_sentence )\n",
    "                log_likelihood_sum += log_likelihood_sentence\n",
    "                total_words += len(sentence.split())\n",
    "        \n",
    "        if total_words >0:\n",
    "        # Calculate average perplexity\n",
    "            average_perplexity = 2 ** (-log_likelihood_sum / total_words)\n",
    "\n",
    "        return perplexity_scores, average_perplexity\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83e18546",
   "metadata": {},
   "source": [
    "### Testing Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "25c713f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup complete. Train corpus: 3_g_Pride and Prejudice - Jane Austen.txt_train.txt, Test corpus: 3_g_Pride and Prejudice - Jane Austen.txt_test.txt\n",
      "141741.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Sample Corpus\n",
    "sample_corpus = \"\"\"\n",
    "This is a simple example. Each line is a sentence.\n",
    "You can add more sentences for better training.\n",
    "Language modeling is an interesting task.\n",
    "\"\"\"\n",
    "\n",
    "# Save the sample corpus to a file\n",
    "# corpus_path = \"sample_corpus.txt\"\n",
    "corpus_path = \"./corpus/Pride and Prejudice - Jane Austen.txt\"\n",
    "\n",
    "# with open(corpus_path, 'w', encoding='utf-8') as file:\n",
    "#     file.write(sample_corpus)\n",
    "\n",
    "# Instantiate the Model\n",
    "model = Model(corpus_path, n_gram_order=3, smoothing_type=\"g\", lambdas=None)\n",
    "\n",
    "# Setup the training and testing corpora\n",
    "model.setup()\n",
    "\n",
    "# Train the model\n",
    "model.train()\n",
    "\n",
    "# Save the model\n",
    "model.save()\n",
    "\n",
    "# Load the model\n",
    "loaded_model = Model(corpus_path)\n",
    "loaded_model.load()\n",
    "# # Display the smoothed probabilities\n",
    "for ngram, prob in loaded_model.probs.items():\n",
    "    print(f\"{ngram}: {prob}\")\n",
    "\n",
    "# # Evaluate on the test corpus\n",
    "perplexity_scores, average_perplexity = loaded_model.evaluate(test = True)\n",
    "\n",
    "# Display the results\n",
    "# print(f\"Perplexity Scores: {perplexity_scores}\")\n",
    "# print(f\"Average Perplexity: {average_perplexity}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f61eaaf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2362b37",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
